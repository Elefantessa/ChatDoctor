{
  "best_global_step": 1400,
  "best_metric": 1.5173088312149048,
  "best_model_checkpoint": "./models/mistral_lora/checkpoint-1400",
  "epoch": 0.8023928501065678,
  "eval_steps": 200,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005731377500761198,
      "grad_norm": 3.1069233417510986,
      "learning_rate": 1.8e-05,
      "loss": 2.917,
      "step": 10
    },
    {
      "epoch": 0.011462755001522397,
      "grad_norm": 0.9090679287910461,
      "learning_rate": 3.8e-05,
      "loss": 2.3594,
      "step": 20
    },
    {
      "epoch": 0.017194132502283594,
      "grad_norm": 0.7709330320358276,
      "learning_rate": 5.8e-05,
      "loss": 2.2213,
      "step": 30
    },
    {
      "epoch": 0.022925510003044793,
      "grad_norm": 0.8078421354293823,
      "learning_rate": 7.800000000000001e-05,
      "loss": 2.1522,
      "step": 40
    },
    {
      "epoch": 0.028656887503805992,
      "grad_norm": 0.9514377117156982,
      "learning_rate": 9.8e-05,
      "loss": 2.0754,
      "step": 50
    },
    {
      "epoch": 0.03438826500456719,
      "grad_norm": 0.8377726078033447,
      "learning_rate": 0.000118,
      "loss": 2.0153,
      "step": 60
    },
    {
      "epoch": 0.04011964250532839,
      "grad_norm": 0.8442384600639343,
      "learning_rate": 0.000138,
      "loss": 1.9703,
      "step": 70
    },
    {
      "epoch": 0.045851020006089586,
      "grad_norm": 0.8014670014381409,
      "learning_rate": 0.00015800000000000002,
      "loss": 1.9689,
      "step": 80
    },
    {
      "epoch": 0.051582397506850786,
      "grad_norm": 0.8160805702209473,
      "learning_rate": 0.00017800000000000002,
      "loss": 1.9328,
      "step": 90
    },
    {
      "epoch": 0.057313775007611985,
      "grad_norm": 0.7570937275886536,
      "learning_rate": 0.00019800000000000002,
      "loss": 1.9226,
      "step": 100
    },
    {
      "epoch": 0.06304515250837318,
      "grad_norm": 0.7881984114646912,
      "learning_rate": 0.00019890577507598785,
      "loss": 1.9361,
      "step": 110
    },
    {
      "epoch": 0.06877653000913438,
      "grad_norm": 0.7556966543197632,
      "learning_rate": 0.00019768996960486325,
      "loss": 1.8491,
      "step": 120
    },
    {
      "epoch": 0.07450790750989558,
      "grad_norm": 0.7753547430038452,
      "learning_rate": 0.0001964741641337386,
      "loss": 1.8811,
      "step": 130
    },
    {
      "epoch": 0.08023928501065677,
      "grad_norm": 0.7425761818885803,
      "learning_rate": 0.000195258358662614,
      "loss": 1.8591,
      "step": 140
    },
    {
      "epoch": 0.08597066251141798,
      "grad_norm": 0.7281302213668823,
      "learning_rate": 0.00019404255319148937,
      "loss": 1.85,
      "step": 150
    },
    {
      "epoch": 0.09170204001217917,
      "grad_norm": 0.7454932928085327,
      "learning_rate": 0.00019282674772036476,
      "loss": 1.8325,
      "step": 160
    },
    {
      "epoch": 0.09743341751294038,
      "grad_norm": 0.7034626007080078,
      "learning_rate": 0.00019161094224924013,
      "loss": 1.837,
      "step": 170
    },
    {
      "epoch": 0.10316479501370157,
      "grad_norm": 0.7664128541946411,
      "learning_rate": 0.00019039513677811552,
      "loss": 1.8107,
      "step": 180
    },
    {
      "epoch": 0.10889617251446278,
      "grad_norm": 0.7584686875343323,
      "learning_rate": 0.0001891793313069909,
      "loss": 1.8228,
      "step": 190
    },
    {
      "epoch": 0.11462755001522397,
      "grad_norm": 0.7120130658149719,
      "learning_rate": 0.00018796352583586628,
      "loss": 1.748,
      "step": 200
    },
    {
      "epoch": 0.11462755001522397,
      "eval_loss": 1.7855041027069092,
      "eval_runtime": 32.5565,
      "eval_samples_per_second": 15.358,
      "eval_steps_per_second": 1.935,
      "step": 200
    },
    {
      "epoch": 0.12035892751598518,
      "grad_norm": 0.7895920276641846,
      "learning_rate": 0.00018674772036474165,
      "loss": 1.7713,
      "step": 210
    },
    {
      "epoch": 0.12609030501674637,
      "grad_norm": 0.716339647769928,
      "learning_rate": 0.00018553191489361704,
      "loss": 1.7827,
      "step": 220
    },
    {
      "epoch": 0.13182168251750756,
      "grad_norm": 0.7361652255058289,
      "learning_rate": 0.0001843161094224924,
      "loss": 1.771,
      "step": 230
    },
    {
      "epoch": 0.13755306001826875,
      "grad_norm": 0.7167447209358215,
      "learning_rate": 0.0001831003039513678,
      "loss": 1.7955,
      "step": 240
    },
    {
      "epoch": 0.14328443751902997,
      "grad_norm": 0.7608683705329895,
      "learning_rate": 0.00018188449848024316,
      "loss": 1.7169,
      "step": 250
    },
    {
      "epoch": 0.14901581501979116,
      "grad_norm": 0.7745716571807861,
      "learning_rate": 0.00018066869300911855,
      "loss": 1.7423,
      "step": 260
    },
    {
      "epoch": 0.15474719252055236,
      "grad_norm": 0.7914153337478638,
      "learning_rate": 0.00017945288753799392,
      "loss": 1.719,
      "step": 270
    },
    {
      "epoch": 0.16047857002131355,
      "grad_norm": 0.7878267765045166,
      "learning_rate": 0.0001782370820668693,
      "loss": 1.7845,
      "step": 280
    },
    {
      "epoch": 0.16620994752207477,
      "grad_norm": 0.7735761404037476,
      "learning_rate": 0.00017702127659574468,
      "loss": 1.7809,
      "step": 290
    },
    {
      "epoch": 0.17194132502283596,
      "grad_norm": 0.7918806672096252,
      "learning_rate": 0.00017580547112462007,
      "loss": 1.745,
      "step": 300
    },
    {
      "epoch": 0.17767270252359715,
      "grad_norm": 0.7545193433761597,
      "learning_rate": 0.00017458966565349546,
      "loss": 1.7541,
      "step": 310
    },
    {
      "epoch": 0.18340408002435835,
      "grad_norm": 0.7576888203620911,
      "learning_rate": 0.00017337386018237083,
      "loss": 1.7547,
      "step": 320
    },
    {
      "epoch": 0.18913545752511957,
      "grad_norm": 0.7277094721794128,
      "learning_rate": 0.00017215805471124622,
      "loss": 1.7337,
      "step": 330
    },
    {
      "epoch": 0.19486683502588076,
      "grad_norm": 0.7330949306488037,
      "learning_rate": 0.0001709422492401216,
      "loss": 1.7345,
      "step": 340
    },
    {
      "epoch": 0.20059821252664195,
      "grad_norm": 0.7547367811203003,
      "learning_rate": 0.00016972644376899698,
      "loss": 1.7075,
      "step": 350
    },
    {
      "epoch": 0.20632959002740314,
      "grad_norm": 0.7472166419029236,
      "learning_rate": 0.00016851063829787235,
      "loss": 1.704,
      "step": 360
    },
    {
      "epoch": 0.21206096752816433,
      "grad_norm": 0.7757447361946106,
      "learning_rate": 0.00016729483282674774,
      "loss": 1.7276,
      "step": 370
    },
    {
      "epoch": 0.21779234502892555,
      "grad_norm": 0.7588571310043335,
      "learning_rate": 0.0001660790273556231,
      "loss": 1.6927,
      "step": 380
    },
    {
      "epoch": 0.22352372252968675,
      "grad_norm": 0.7839248776435852,
      "learning_rate": 0.0001648632218844985,
      "loss": 1.7293,
      "step": 390
    },
    {
      "epoch": 0.22925510003044794,
      "grad_norm": 0.7774403691291809,
      "learning_rate": 0.00016364741641337386,
      "loss": 1.7045,
      "step": 400
    },
    {
      "epoch": 0.22925510003044794,
      "eval_loss": 1.6817225217819214,
      "eval_runtime": 32.5691,
      "eval_samples_per_second": 15.352,
      "eval_steps_per_second": 1.934,
      "step": 400
    },
    {
      "epoch": 0.23498647753120913,
      "grad_norm": 0.7389959692955017,
      "learning_rate": 0.00016243161094224925,
      "loss": 1.6891,
      "step": 410
    },
    {
      "epoch": 0.24071785503197035,
      "grad_norm": 0.7695446610450745,
      "learning_rate": 0.00016121580547112462,
      "loss": 1.7144,
      "step": 420
    },
    {
      "epoch": 0.24644923253273154,
      "grad_norm": 0.7400907874107361,
      "learning_rate": 0.00016,
      "loss": 1.6807,
      "step": 430
    },
    {
      "epoch": 0.25218061003349274,
      "grad_norm": 0.6959806084632874,
      "learning_rate": 0.00015878419452887538,
      "loss": 1.6757,
      "step": 440
    },
    {
      "epoch": 0.25791198753425393,
      "grad_norm": 0.7641057372093201,
      "learning_rate": 0.00015756838905775077,
      "loss": 1.6145,
      "step": 450
    },
    {
      "epoch": 0.2636433650350151,
      "grad_norm": 0.7982035279273987,
      "learning_rate": 0.00015635258358662614,
      "loss": 1.6259,
      "step": 460
    },
    {
      "epoch": 0.2693747425357763,
      "grad_norm": 0.7586490511894226,
      "learning_rate": 0.00015513677811550153,
      "loss": 1.6705,
      "step": 470
    },
    {
      "epoch": 0.2751061200365375,
      "grad_norm": 0.7270610928535461,
      "learning_rate": 0.0001539209726443769,
      "loss": 1.6732,
      "step": 480
    },
    {
      "epoch": 0.28083749753729875,
      "grad_norm": 0.746242105960846,
      "learning_rate": 0.0001527051671732523,
      "loss": 1.6899,
      "step": 490
    },
    {
      "epoch": 0.28656887503805994,
      "grad_norm": 0.7505584955215454,
      "learning_rate": 0.00015148936170212765,
      "loss": 1.636,
      "step": 500
    },
    {
      "epoch": 0.29230025253882114,
      "grad_norm": 0.7374690771102905,
      "learning_rate": 0.00015027355623100305,
      "loss": 1.6822,
      "step": 510
    },
    {
      "epoch": 0.29803163003958233,
      "grad_norm": 0.8566937446594238,
      "learning_rate": 0.0001490577507598784,
      "loss": 1.6552,
      "step": 520
    },
    {
      "epoch": 0.3037630075403435,
      "grad_norm": 0.7563741207122803,
      "learning_rate": 0.0001478419452887538,
      "loss": 1.6594,
      "step": 530
    },
    {
      "epoch": 0.3094943850411047,
      "grad_norm": 0.7411899566650391,
      "learning_rate": 0.00014662613981762917,
      "loss": 1.712,
      "step": 540
    },
    {
      "epoch": 0.3152257625418659,
      "grad_norm": 0.7944722175598145,
      "learning_rate": 0.00014541033434650456,
      "loss": 1.6497,
      "step": 550
    },
    {
      "epoch": 0.3209571400426271,
      "grad_norm": 0.7380863428115845,
      "learning_rate": 0.00014419452887537995,
      "loss": 1.6632,
      "step": 560
    },
    {
      "epoch": 0.32668851754338835,
      "grad_norm": 0.7339511513710022,
      "learning_rate": 0.00014297872340425532,
      "loss": 1.5953,
      "step": 570
    },
    {
      "epoch": 0.33241989504414954,
      "grad_norm": 0.7596566081047058,
      "learning_rate": 0.0001417629179331307,
      "loss": 1.664,
      "step": 580
    },
    {
      "epoch": 0.33815127254491073,
      "grad_norm": 0.7663105726242065,
      "learning_rate": 0.00014054711246200608,
      "loss": 1.6808,
      "step": 590
    },
    {
      "epoch": 0.3438826500456719,
      "grad_norm": 0.7778312563896179,
      "learning_rate": 0.00013933130699088147,
      "loss": 1.6362,
      "step": 600
    },
    {
      "epoch": 0.3438826500456719,
      "eval_loss": 1.6238659620285034,
      "eval_runtime": 32.595,
      "eval_samples_per_second": 15.34,
      "eval_steps_per_second": 1.933,
      "step": 600
    },
    {
      "epoch": 0.3496140275464331,
      "grad_norm": 0.7411326766014099,
      "learning_rate": 0.00013811550151975686,
      "loss": 1.636,
      "step": 610
    },
    {
      "epoch": 0.3553454050471943,
      "grad_norm": 0.8162656426429749,
      "learning_rate": 0.00013689969604863223,
      "loss": 1.6711,
      "step": 620
    },
    {
      "epoch": 0.3610767825479555,
      "grad_norm": 0.75308758020401,
      "learning_rate": 0.00013568389057750762,
      "loss": 1.6487,
      "step": 630
    },
    {
      "epoch": 0.3668081600487167,
      "grad_norm": 0.748440682888031,
      "learning_rate": 0.000134468085106383,
      "loss": 1.6359,
      "step": 640
    },
    {
      "epoch": 0.3725395375494779,
      "grad_norm": 0.838636577129364,
      "learning_rate": 0.00013325227963525838,
      "loss": 1.6293,
      "step": 650
    },
    {
      "epoch": 0.37827091505023913,
      "grad_norm": 0.7757467031478882,
      "learning_rate": 0.00013203647416413375,
      "loss": 1.6685,
      "step": 660
    },
    {
      "epoch": 0.3840022925510003,
      "grad_norm": 0.7520270943641663,
      "learning_rate": 0.00013082066869300914,
      "loss": 1.6282,
      "step": 670
    },
    {
      "epoch": 0.3897336700517615,
      "grad_norm": 0.7665427923202515,
      "learning_rate": 0.0001296048632218845,
      "loss": 1.6417,
      "step": 680
    },
    {
      "epoch": 0.3954650475525227,
      "grad_norm": 0.7753720283508301,
      "learning_rate": 0.0001283890577507599,
      "loss": 1.6274,
      "step": 690
    },
    {
      "epoch": 0.4011964250532839,
      "grad_norm": 0.789506196975708,
      "learning_rate": 0.00012717325227963526,
      "loss": 1.719,
      "step": 700
    },
    {
      "epoch": 0.4069278025540451,
      "grad_norm": 0.7810857892036438,
      "learning_rate": 0.00012595744680851065,
      "loss": 1.641,
      "step": 710
    },
    {
      "epoch": 0.4126591800548063,
      "grad_norm": 0.7363224029541016,
      "learning_rate": 0.00012474164133738602,
      "loss": 1.606,
      "step": 720
    },
    {
      "epoch": 0.4183905575555675,
      "grad_norm": 0.7625836133956909,
      "learning_rate": 0.0001235258358662614,
      "loss": 1.6432,
      "step": 730
    },
    {
      "epoch": 0.42412193505632867,
      "grad_norm": 0.759894847869873,
      "learning_rate": 0.00012231003039513678,
      "loss": 1.5921,
      "step": 740
    },
    {
      "epoch": 0.4298533125570899,
      "grad_norm": 0.7793185114860535,
      "learning_rate": 0.00012109422492401217,
      "loss": 1.5751,
      "step": 750
    },
    {
      "epoch": 0.4355846900578511,
      "grad_norm": 0.7864080667495728,
      "learning_rate": 0.00011987841945288754,
      "loss": 1.6085,
      "step": 760
    },
    {
      "epoch": 0.4413160675586123,
      "grad_norm": 0.7580230832099915,
      "learning_rate": 0.00011866261398176293,
      "loss": 1.5912,
      "step": 770
    },
    {
      "epoch": 0.4470474450593735,
      "grad_norm": 0.7165662050247192,
      "learning_rate": 0.0001174468085106383,
      "loss": 1.6616,
      "step": 780
    },
    {
      "epoch": 0.4527788225601347,
      "grad_norm": 0.7856044173240662,
      "learning_rate": 0.00011623100303951369,
      "loss": 1.6041,
      "step": 790
    },
    {
      "epoch": 0.4585102000608959,
      "grad_norm": 0.7606980800628662,
      "learning_rate": 0.00011501519756838905,
      "loss": 1.6107,
      "step": 800
    },
    {
      "epoch": 0.4585102000608959,
      "eval_loss": 1.5866879224777222,
      "eval_runtime": 32.5359,
      "eval_samples_per_second": 15.368,
      "eval_steps_per_second": 1.936,
      "step": 800
    },
    {
      "epoch": 0.46424157756165707,
      "grad_norm": 0.7541122436523438,
      "learning_rate": 0.00011379939209726445,
      "loss": 1.6094,
      "step": 810
    },
    {
      "epoch": 0.46997295506241826,
      "grad_norm": 0.8105659484863281,
      "learning_rate": 0.00011258358662613981,
      "loss": 1.6157,
      "step": 820
    },
    {
      "epoch": 0.47570433256317946,
      "grad_norm": 0.7817502021789551,
      "learning_rate": 0.0001113677811550152,
      "loss": 1.5732,
      "step": 830
    },
    {
      "epoch": 0.4814357100639407,
      "grad_norm": 0.8142560124397278,
      "learning_rate": 0.00011015197568389057,
      "loss": 1.6204,
      "step": 840
    },
    {
      "epoch": 0.4871670875647019,
      "grad_norm": 0.7628698945045471,
      "learning_rate": 0.00010893617021276596,
      "loss": 1.5954,
      "step": 850
    },
    {
      "epoch": 0.4928984650654631,
      "grad_norm": 0.7867806553840637,
      "learning_rate": 0.00010772036474164133,
      "loss": 1.5805,
      "step": 860
    },
    {
      "epoch": 0.4986298425662243,
      "grad_norm": 0.7651217579841614,
      "learning_rate": 0.00010650455927051672,
      "loss": 1.6155,
      "step": 870
    },
    {
      "epoch": 0.5043612200669855,
      "grad_norm": 0.7834661602973938,
      "learning_rate": 0.00010528875379939209,
      "loss": 1.6152,
      "step": 880
    },
    {
      "epoch": 0.5100925975677467,
      "grad_norm": 0.7669865489006042,
      "learning_rate": 0.00010407294832826748,
      "loss": 1.624,
      "step": 890
    },
    {
      "epoch": 0.5158239750685079,
      "grad_norm": 0.7857032418251038,
      "learning_rate": 0.00010285714285714286,
      "loss": 1.5826,
      "step": 900
    },
    {
      "epoch": 0.5215553525692691,
      "grad_norm": 0.8129000067710876,
      "learning_rate": 0.00010164133738601824,
      "loss": 1.5919,
      "step": 910
    },
    {
      "epoch": 0.5272867300700302,
      "grad_norm": 0.7594139575958252,
      "learning_rate": 0.00010042553191489362,
      "loss": 1.5882,
      "step": 920
    },
    {
      "epoch": 0.5330181075707915,
      "grad_norm": 0.736889123916626,
      "learning_rate": 9.920972644376901e-05,
      "loss": 1.6021,
      "step": 930
    },
    {
      "epoch": 0.5387494850715526,
      "grad_norm": 0.7748977541923523,
      "learning_rate": 9.799392097264439e-05,
      "loss": 1.6128,
      "step": 940
    },
    {
      "epoch": 0.5444808625723139,
      "grad_norm": 0.7830458283424377,
      "learning_rate": 9.677811550151977e-05,
      "loss": 1.6109,
      "step": 950
    },
    {
      "epoch": 0.550212240073075,
      "grad_norm": 0.7506130337715149,
      "learning_rate": 9.556231003039515e-05,
      "loss": 1.6298,
      "step": 960
    },
    {
      "epoch": 0.5559436175738363,
      "grad_norm": 0.7437844276428223,
      "learning_rate": 9.434650455927053e-05,
      "loss": 1.5155,
      "step": 970
    },
    {
      "epoch": 0.5616749950745975,
      "grad_norm": 0.7899228930473328,
      "learning_rate": 9.31306990881459e-05,
      "loss": 1.5448,
      "step": 980
    },
    {
      "epoch": 0.5674063725753586,
      "grad_norm": 0.7259218096733093,
      "learning_rate": 9.191489361702128e-05,
      "loss": 1.5545,
      "step": 990
    },
    {
      "epoch": 0.5731377500761199,
      "grad_norm": 0.742620587348938,
      "learning_rate": 9.069908814589666e-05,
      "loss": 1.577,
      "step": 1000
    },
    {
      "epoch": 0.5731377500761199,
      "eval_loss": 1.5592234134674072,
      "eval_runtime": 32.7876,
      "eval_samples_per_second": 15.25,
      "eval_steps_per_second": 1.921,
      "step": 1000
    },
    {
      "epoch": 0.578869127576881,
      "grad_norm": 0.8355467915534973,
      "learning_rate": 8.948328267477204e-05,
      "loss": 1.575,
      "step": 1010
    },
    {
      "epoch": 0.5846005050776423,
      "grad_norm": 0.744086742401123,
      "learning_rate": 8.826747720364742e-05,
      "loss": 1.5978,
      "step": 1020
    },
    {
      "epoch": 0.5903318825784034,
      "grad_norm": 0.8270880579948425,
      "learning_rate": 8.70516717325228e-05,
      "loss": 1.5796,
      "step": 1030
    },
    {
      "epoch": 0.5960632600791647,
      "grad_norm": 0.7621000409126282,
      "learning_rate": 8.583586626139818e-05,
      "loss": 1.5847,
      "step": 1040
    },
    {
      "epoch": 0.6017946375799258,
      "grad_norm": 0.8066973090171814,
      "learning_rate": 8.462006079027356e-05,
      "loss": 1.5917,
      "step": 1050
    },
    {
      "epoch": 0.607526015080687,
      "grad_norm": 0.7475725412368774,
      "learning_rate": 8.340425531914894e-05,
      "loss": 1.5866,
      "step": 1060
    },
    {
      "epoch": 0.6132573925814483,
      "grad_norm": 0.8017420768737793,
      "learning_rate": 8.218844984802432e-05,
      "loss": 1.5708,
      "step": 1070
    },
    {
      "epoch": 0.6189887700822094,
      "grad_norm": 0.7707577347755432,
      "learning_rate": 8.09726443768997e-05,
      "loss": 1.518,
      "step": 1080
    },
    {
      "epoch": 0.6247201475829707,
      "grad_norm": 0.7892317175865173,
      "learning_rate": 7.975683890577507e-05,
      "loss": 1.5633,
      "step": 1090
    },
    {
      "epoch": 0.6304515250837318,
      "grad_norm": 0.7983750700950623,
      "learning_rate": 7.854103343465045e-05,
      "loss": 1.5766,
      "step": 1100
    },
    {
      "epoch": 0.6361829025844931,
      "grad_norm": 0.8146657943725586,
      "learning_rate": 7.732522796352583e-05,
      "loss": 1.5498,
      "step": 1110
    },
    {
      "epoch": 0.6419142800852542,
      "grad_norm": 0.7757167816162109,
      "learning_rate": 7.610942249240121e-05,
      "loss": 1.5912,
      "step": 1120
    },
    {
      "epoch": 0.6476456575860154,
      "grad_norm": 0.8310224413871765,
      "learning_rate": 7.489361702127659e-05,
      "loss": 1.5543,
      "step": 1130
    },
    {
      "epoch": 0.6533770350867767,
      "grad_norm": 0.7600279450416565,
      "learning_rate": 7.367781155015197e-05,
      "loss": 1.5498,
      "step": 1140
    },
    {
      "epoch": 0.6591084125875378,
      "grad_norm": 0.7787767052650452,
      "learning_rate": 7.246200607902736e-05,
      "loss": 1.5762,
      "step": 1150
    },
    {
      "epoch": 0.6648397900882991,
      "grad_norm": 0.833270788192749,
      "learning_rate": 7.124620060790274e-05,
      "loss": 1.525,
      "step": 1160
    },
    {
      "epoch": 0.6705711675890602,
      "grad_norm": 0.7798787355422974,
      "learning_rate": 7.003039513677812e-05,
      "loss": 1.5457,
      "step": 1170
    },
    {
      "epoch": 0.6763025450898215,
      "grad_norm": 0.7275974154472351,
      "learning_rate": 6.88145896656535e-05,
      "loss": 1.5624,
      "step": 1180
    },
    {
      "epoch": 0.6820339225905826,
      "grad_norm": 0.8188235759735107,
      "learning_rate": 6.759878419452888e-05,
      "loss": 1.5304,
      "step": 1190
    },
    {
      "epoch": 0.6877653000913438,
      "grad_norm": 0.754404604434967,
      "learning_rate": 6.638297872340426e-05,
      "loss": 1.5316,
      "step": 1200
    },
    {
      "epoch": 0.6877653000913438,
      "eval_loss": 1.5341664552688599,
      "eval_runtime": 32.5781,
      "eval_samples_per_second": 15.348,
      "eval_steps_per_second": 1.934,
      "step": 1200
    },
    {
      "epoch": 0.693496677592105,
      "grad_norm": 0.7735450267791748,
      "learning_rate": 6.516717325227964e-05,
      "loss": 1.5829,
      "step": 1210
    },
    {
      "epoch": 0.6992280550928662,
      "grad_norm": 0.7582172751426697,
      "learning_rate": 6.395136778115502e-05,
      "loss": 1.5355,
      "step": 1220
    },
    {
      "epoch": 0.7049594325936275,
      "grad_norm": 0.8353935480117798,
      "learning_rate": 6.27355623100304e-05,
      "loss": 1.5716,
      "step": 1230
    },
    {
      "epoch": 0.7106908100943886,
      "grad_norm": 0.7649620175361633,
      "learning_rate": 6.151975683890577e-05,
      "loss": 1.5597,
      "step": 1240
    },
    {
      "epoch": 0.7164221875951499,
      "grad_norm": 0.7791489958763123,
      "learning_rate": 6.030395136778115e-05,
      "loss": 1.4934,
      "step": 1250
    },
    {
      "epoch": 0.722153565095911,
      "grad_norm": 0.784275233745575,
      "learning_rate": 5.908814589665653e-05,
      "loss": 1.5695,
      "step": 1260
    },
    {
      "epoch": 0.7278849425966722,
      "grad_norm": 0.7656111121177673,
      "learning_rate": 5.787234042553191e-05,
      "loss": 1.5789,
      "step": 1270
    },
    {
      "epoch": 0.7336163200974334,
      "grad_norm": 0.7921946048736572,
      "learning_rate": 5.665653495440729e-05,
      "loss": 1.5635,
      "step": 1280
    },
    {
      "epoch": 0.7393476975981946,
      "grad_norm": 0.8356225490570068,
      "learning_rate": 5.544072948328268e-05,
      "loss": 1.5764,
      "step": 1290
    },
    {
      "epoch": 0.7450790750989558,
      "grad_norm": 0.8137076497077942,
      "learning_rate": 5.422492401215806e-05,
      "loss": 1.5744,
      "step": 1300
    },
    {
      "epoch": 0.750810452599717,
      "grad_norm": 0.7936978340148926,
      "learning_rate": 5.300911854103344e-05,
      "loss": 1.5551,
      "step": 1310
    },
    {
      "epoch": 0.7565418301004783,
      "grad_norm": 0.8108140826225281,
      "learning_rate": 5.179331306990882e-05,
      "loss": 1.5516,
      "step": 1320
    },
    {
      "epoch": 0.7622732076012394,
      "grad_norm": 0.7925760746002197,
      "learning_rate": 5.05775075987842e-05,
      "loss": 1.5924,
      "step": 1330
    },
    {
      "epoch": 0.7680045851020006,
      "grad_norm": 0.8068075180053711,
      "learning_rate": 4.936170212765958e-05,
      "loss": 1.5551,
      "step": 1340
    },
    {
      "epoch": 0.7737359626027618,
      "grad_norm": 0.8092781901359558,
      "learning_rate": 4.814589665653496e-05,
      "loss": 1.5293,
      "step": 1350
    },
    {
      "epoch": 0.779467340103523,
      "grad_norm": 0.7759910225868225,
      "learning_rate": 4.693009118541034e-05,
      "loss": 1.5579,
      "step": 1360
    },
    {
      "epoch": 0.7851987176042842,
      "grad_norm": 0.7827877402305603,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 1.5442,
      "step": 1370
    },
    {
      "epoch": 0.7909300951050454,
      "grad_norm": 0.7828748822212219,
      "learning_rate": 4.4498480243161095e-05,
      "loss": 1.543,
      "step": 1380
    },
    {
      "epoch": 0.7966614726058066,
      "grad_norm": 0.77023845911026,
      "learning_rate": 4.3282674772036474e-05,
      "loss": 1.5511,
      "step": 1390
    },
    {
      "epoch": 0.8023928501065678,
      "grad_norm": 0.8090416789054871,
      "learning_rate": 4.206686930091185e-05,
      "loss": 1.547,
      "step": 1400
    },
    {
      "epoch": 0.8023928501065678,
      "eval_loss": 1.5173088312149048,
      "eval_runtime": 32.5697,
      "eval_samples_per_second": 15.352,
      "eval_steps_per_second": 1.934,
      "step": 1400
    }
  ],
  "logging_steps": 10,
  "max_steps": 1745,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4377930555533558e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
